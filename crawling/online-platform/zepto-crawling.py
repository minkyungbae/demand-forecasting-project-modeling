import time
import pandas as pd
import os
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from datetime import datetime

# 1. ë¸Œë¼ìš°ì € ì„¤ì •
chrome_options = Options()
# chrome_options.add_argument("--headless")  # í™”ë©´ ì—†ì´ ì‹¤í–‰í•˜ê³  ì‹¶ì„ ë•Œ ì£¼ì„ ì œê±°
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36")

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)

def crawl_zepto_products(url):
    driver.get(url)
    wait = WebDriverWait(driver, 10)
    
    # ìƒí’ˆ ë°ì´í„° ì €ì¥ ë¦¬ìŠ¤íŠ¸
    product_list = []

    # ë™ì  ë¡œë”© ëŒ€ì‘: ìŠ¤í¬ë¡¤ ë‚´ë¦¬ê¸°
    last_height = driver.execute_script("return document.body.scrollHeight")
    for _ in range(5):  # í•„ìš”ì— ë”°ë¼ ë°˜ë³µ íšŸìˆ˜ ì¡°ì ˆ
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)
        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            break
        last_height = new_height

    # ìƒí’ˆ ì»¨í…Œì´ë„ˆ ì°¾ê¸° (ì œê³µëœ HTMLì˜ í´ë˜ìŠ¤ B4vNQ í™œìš©)
    # ë²”ìš© ì„ íƒì: [class*='ProductCard'], .product-item, a[href*='/pn/']
    items = driver.find_elements(By.CSS_SELECTOR, "a.B4vNQ, [data-testid='product-card'], .product-item")

    for item in items:
        try:
            # 1. ìƒí’ˆëª… (data-slot-id ìš°ì„ , ì‹¤íŒ¨ì‹œ ë²”ìš© í´ë˜ìŠ¤)
            name = item.find_element(By.CSS_SELECTOR, "div[data-slot-id='ProductName'] span, .product-title, h3").text
            
            # 2. í• ì¸ëœ ê°€ê²© (í˜„ì¬ ê°€ê²©)
            try:
                price = item.find_element(By.CSS_SELECTOR, "span.cptQT7, [data-slot-id='EdlpPrice'] span:first-child, .price").text
            except:
                price = "N/A"

            # 3. ì›ë˜ ê°€ê²© (ì·¨ì†Œì„  ê°€ê²©)
            try:
                original_price = item.find_element(By.CSS_SELECTOR, "span.cx3iWL, .strike, .original-price, del").text
            except:
                original_price = price # í• ì¸ì´ ì—†ìœ¼ë©´ í˜„ì¬ê°€ì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬

            # 4. í• ì¸ ì •ë³´ (í• ì¸ìœ¨ ë˜ëŠ” í• ì¸ ê¸ˆì•¡)
            try:
                discount = item.find_element(By.CSS_SELECTOR, ".cYCsFo, .discount-badge, [class*='discount']").text.replace('\n', ' ')
            except:
                discount = "0%"

            # 5. í’ˆì ˆ ì—¬ë¶€ (data-is-out-of-stock ì†ì„± í™•ì¸)
            # container ë‚´ë¶€ì˜ íŠ¹ì • div ì†ì„± í™•ì¸
            try:
                out_of_stock_attr = item.find_element(By.XPATH, ".//div[@data-is-out-of-stock]").get_attribute("data-is-out-of-stock")
                is_sold_out = "Yes" if out_of_stock_attr == "true" else "No"
            except:
                is_sold_out = "No"

            # 6. ë¬´ê²Œ/ë‹¨ìœ„
            try:
                weight = item.find_element(By.CSS_SELECTOR, "div[data-slot-id='PackSize'] span, .unit, .quantity").text
            except:
                weight = "N/A"

            # 7. ìƒí’ˆ êµ¬ë§¤ URL
            product_url = item.get_attribute("href")

            product_list.append({
                "ìƒí’ˆëª…": name,
                "í˜„ì¬ ê°€ê²©": price,
                "ì›ë˜ ê°€ê²©": original_price,
                "í• ì¸ìœ¨": discount,
                "í’ˆì ˆ ì—¬ë¶€": is_sold_out,
                "ë¬´ê²Œ/ë‹¨ìœ„": weight,
                "ìƒí’ˆ êµ¬ë§¤ URL": product_url
            })
        except Exception as e:
            continue # ë°ì´í„°ê°€ ë¶ˆì™„ì „í•œ ìƒí’ˆì€ ê±´ë„ˆëœ€

    return product_list

# ì‹¤í–‰
target_url = "https://www.zepto.com/cn/fruits-vegetables/fresh-vegetables/cid/64374cfe-d06f-4a01-898e-c07c46462c36/scid/e78a8422-5f20-4e4b-9a9f-22a0e53962e3"
data = crawl_zepto_products(target_url)

# ë°ì´í„°í”„ë ˆì„ ë³€í™˜ ë° ì €ì¥
# 1. ì €ì¥í•  ë””ë ‰í† ë¦¬ ì„¤ì • ë° ìƒì„±
save_dir = "crawling/online-platform/results/zepto"
if not os.path.exists(save_dir):
    os.makedirs(save_dir)

# 2. ì˜¤ëŠ˜ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
today_date = datetime.now().strftime("%y%m%d") # 251218

# 3. íŒŒì¼ ìˆœë²ˆ(Execution Count) ê³„ì‚°
# í•´ë‹¹ í´ë” ë‚´ì˜ .csv íŒŒì¼ ê°œìˆ˜ë¥¼ í™•ì¸í•˜ì—¬ ë‹¤ìŒ ë²ˆí˜¸ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.
existing_files = [f for f in os.listdir(save_dir) if f.endswith(".csv")]
run_count = len(existing_files) + 1

# 4. íŒŒì¼ëª… ì¡°í•© (ìˆœë²ˆ_zepto_ë‚ ì§œ.csv)
# :02dëŠ” ìˆ«ìë¥¼ ë‘ ìë¦¬ë¡œ ë§ì¶¤ (ì˜ˆ: 1 -> 01, 10 -> 10)
file_name = f"{run_count:02d}_zepto_{today_date}.csv"
save_path = os.path.join(save_dir, file_name)

# 5. ë°ì´í„°í”„ë ˆì„ ë³€í™˜ ë° ì €ì¥
df = pd.DataFrame(data)
df.to_csv(save_path, index=False, encoding="utf-8-sig")

print("-" * 30)
print(f"âœ… ì €ì¥ ì™„ë£Œ: {save_path}")
print(f"ğŸ“Š ìˆ˜ì§‘ëœ ìƒí’ˆ ê°œìˆ˜: {len(df)}ê°œ")
print("-" * 30)

driver.quit()